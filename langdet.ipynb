{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"trainingData.csv\")\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels[\"Language\"])\n",
    "labels[\"Language\"] = le.transform(labels[\"Language\"])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = []\n",
    "train_base_dir = \"Training data\"\n",
    "for direc in os.listdir(\"Training data\"):\n",
    "  train_dirs.append(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "# train_data = []\n",
    "pbar = tqdm(total=66176)\n",
    "for i, direc in enumerate(train_dirs):\n",
    "    label = labels[labels[\"Sample Filename\"] == direc][\"Language\"].item()\n",
    "#     y, sr = librosa.load(train_base_dir + \"/\" + direc)\n",
    "#     train_data.append(librosa.feature.melspectrogram(y=y, sr=sr))\n",
    "    train_labels.append(label)\n",
    "    pbar.update(1)\n",
    "pbar.close()    \n",
    "labels = np.array(train_labels)\n",
    "# train_data = np.array(train_data)\n",
    "# np.save(\"train_data.npy\", train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"labels.npy\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"traindata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66176, 40, 430)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data[:,:,50:250]\n",
    "print(data.shape)\n",
    "max(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60176\n"
     ]
    }
   ],
   "source": [
    "test_size = 6000\n",
    "train_size = data.shape[0] - test_size\n",
    "print(train_size)\n",
    "train = data[:train_size, :, :]\n",
    "train_label = labels[:train_size]\n",
    "test = data[train_size:, :, :]\n",
    "test_label = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60176, 40, 430)\n",
      "(60176,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "# train_label = np.array(train_label)\n",
    "print(train_label.shape)\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 40, 430)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "# test_label = np.array(test_label)\n",
    "test_label.shape\n",
    "min(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, train, label):\n",
    "        self.train = train\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train = torch.Tensor(self.train[idx])\n",
    "        train = train.transpose(0,1)\n",
    "        train = train.to(DEVICE)\n",
    "        label = self.label[idx]\n",
    "#         label = label + 1\n",
    "        label = label.astype(np.float)\n",
    "#         print(label)\n",
    "        label = torch.tensor(label)\n",
    "        label = label.to(DEVICE)\n",
    "        return(train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, test):\n",
    "    self.test = test\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.test.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    test = torch.Tensor(self.test[idx])\n",
    "    test = test.to(DEVICE)\n",
    "#     test = test.unsqueeze(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train, train_label)\n",
    "test_dataset = TestDataset(test)\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_sampler=BatchSampler(RandomSampler(train_dataset), train_batch_size, False))\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(104., device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = iter(train_loader).next()[1]\n",
    "# a = list(a)\n",
    "# torch.cat(a)\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size,hidden_size, nlayers):\n",
    "        super(DetectionModel,self).__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers=nlayers\n",
    "        self.rnn = nn.LSTM(input_size = embed_size,hidden_size=hidden_size,num_layers=nlayers, bidirectional=True, batch_first=True) # Recurrent network\n",
    "        self.scoring = nn.Linear(hidden_size * 2,vocab_size) # Projection layer\n",
    "        \n",
    "    def forward(self, seq_batch):\n",
    "        batch_size = seq_batch.size(0)\n",
    "#         print(batch_size)\n",
    "        embed = seq_batch #L x N x E\n",
    "        hidden = None\n",
    "        output_lstm,hidden = self.rnn(embed,hidden) #L x N x H\n",
    "#         print(output_lstm.shape)\n",
    "#         output_lstm_flatten = output_lstm.contiguous().view(-1,self.hidden_size * 2) #(L*N) x H\n",
    "#         output_flatten = self.scoring(output_lstm) #(L*N) x V\n",
    "        return output_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    batch_id=0\n",
    "    for inputs,targets in train_loader:\n",
    "        batch_loss = []\n",
    "        batch_id+=1\n",
    "#         inputs = inputs.to(DEVICE)\n",
    "#         targets = targets.to(DEVICE)\n",
    "        outputs = model(inputs) # 3D\n",
    "#         print(outputs.shape)\n",
    "#         outputs = outputs[:, -1, :] # pull out the last layer\n",
    "        outputs = torch.sum(outputs, dim=1)\n",
    "#         print(outputs.shape)\n",
    "#         print(torch.argmax(outputs, dim=1))\n",
    "#         print(targets)\n",
    "#         print(targets.shape)\n",
    "#         print(targets)\n",
    "        loss = criterion(outputs,targets.long()) # Loss of the flattened outputs\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "#         print(loss.item())\n",
    "        torch.cuda.empty_cache()\n",
    "        if batch_id % 20 == 0:\n",
    "            lpw = np.mean(batch_loss)\n",
    "            torch.save(model, \"model.pt\")\n",
    "            print(\"At batch\",batch_id)\n",
    "            print(\"Training loss :\",lpw)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "langcount = 176\n",
    "model = DetectionModel(langcount,40,176,5)\n",
    "# model = torch.load(\"model.pt\")\n",
    "model = model.to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=0.01, weight_decay=1e-6)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "/jet/var/python/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type DetectionModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At batch 20\n",
      "Training loss : 18.6175479889\n",
      "At batch 40\n",
      "Training loss : 8.58160591125\n",
      "At batch 60\n",
      "Training loss : 6.46694469452\n",
      "At batch 80\n",
      "Training loss : 5.85277271271\n",
      "At batch 100\n",
      "Training loss : 5.95144033432\n",
      "At batch 120\n",
      "Training loss : 5.69115924835\n",
      "At batch 140\n",
      "Training loss : 5.72989702225\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    train_epoch(model, optimizer, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
