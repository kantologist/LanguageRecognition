{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Filename</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000kouqjfnk.mp3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000w3fewuqj.mp3</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ylhu4sxl.mp3</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0014x3zvjrl.mp3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001xjmtk2wx.mp3</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Filename  Language\n",
       "0  000kouqjfnk.mp3        56\n",
       "1  000w3fewuqj.mp3       151\n",
       "2  000ylhu4sxl.mp3       155\n",
       "3  0014x3zvjrl.mp3        35\n",
       "4  001xjmtk2wx.mp3        69"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"trainingData.csv\")\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels[\"Language\"])\n",
    "labels[\"Language\"] = le.transform(labels[\"Language\"])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = []\n",
    "train_base_dir = \"Training data\"\n",
    "for direc in os.listdir(\"Training data\"):\n",
    "  train_dirs.append(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66176/66176 [04:58<00:00, 222.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "pbar = tqdm(total=66176)\n",
    "for i, direc in enumerate(train_dirs):\n",
    "    label = labels[labels[\"Sample Filename\"] == direc][\"Language\"].item()\n",
    "    train_labels.append(label)\n",
    "    pbar.update(1)\n",
    "pbar.close()    \n",
    "labels = np.array(train_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"traindata.npy\")\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "max(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46176\n"
     ]
    }
   ],
   "source": [
    "test_size = 20000\n",
    "train_size = data.shape[0] - test_size\n",
    "print(train_size)\n",
    "train = data[:train_size, :, :]\n",
    "train_label = labels[:train_size]\n",
    "test = data[train_size:, :, :]\n",
    "test_label = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "train_label.shape\n",
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape\n",
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, train, label):\n",
    "        self.train = train\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train = torch.Tensor(self.train[idx])\n",
    "        train = train.transpose(0,1)\n",
    "#         train = train.to(DEVICE)\n",
    "        label = self.label[idx]\n",
    "#         label = torch.Tensor(label)\n",
    "#         label = label.to(DEVICE)\n",
    "        return(train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, test):\n",
    "    self.test = test\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.test.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    test = torch.Tensor(self.test[idx])\n",
    "    test = test.to(DEVICE)\n",
    "#     test = test.unsqueeze(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train, train_label)\n",
    "test_dataset = TestDataset(test)\n",
    "train_batch_size = 100\n",
    "test_batch_size = 100\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_sampler=BatchSampler(RandomSampler(train_dataset), train_batch_size, False))\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-535.1118,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-535.1118,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-378.0182,  134.4436,   24.9814,  ...,   -4.6965,  -11.2445,\n",
       "            -10.4372],\n",
       "          ...,\n",
       "          [-477.9030,   27.7392,   39.3758,  ...,   -0.7092,   -2.7948,\n",
       "              6.7452],\n",
       "          [-386.8672,   -9.0076,   45.1327,  ...,   -1.6875,   -7.7957,\n",
       "              7.7620],\n",
       "          [-241.6925,   35.2376,   39.2086,  ...,   -2.5565,   -6.4098,\n",
       "             -4.5064]],\n",
       " \n",
       "         [[-557.1776,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-557.1776,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-487.6949,   40.7268,   14.3401,  ...,    4.1408,    7.9077,\n",
       "             -3.0193],\n",
       "          ...,\n",
       "          [-137.7886,  153.1989,  -44.0398,  ...,   19.6007,   13.9441,\n",
       "             16.2345],\n",
       "          [-155.7539,  138.5114,  -24.6877,  ...,   14.0575,    4.5114,\n",
       "              2.0601],\n",
       "          [-149.8466,   92.1175,   18.5430,  ...,   15.6792,   -1.2293,\n",
       "             -3.2768]],\n",
       " \n",
       "         [[-534.8783,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-506.7862,   38.5843,   35.2575,  ...,    0.7697,    0.8766,\n",
       "              0.8042],\n",
       "          [-419.2976,   99.7158,   46.2710,  ...,   -1.2983,    0.5550,\n",
       "              4.1085],\n",
       "          ...,\n",
       "          [-534.8783,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-534.8783,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-534.8783,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-517.5014,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-517.5014,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-396.9883,  126.2940,   51.3705,  ...,    2.1163,    4.7654,\n",
       "              1.6807],\n",
       "          ...,\n",
       "          [-280.3345,  102.4148,    1.7758,  ...,   -3.4264,    5.9291,\n",
       "             -2.7369],\n",
       "          [-275.0283,   89.2514,   -5.4219,  ...,    7.7732,    6.9743,\n",
       "             -8.9059],\n",
       "          [-247.0254,  108.9759,   21.8456,  ...,    6.4215,   -2.0737,\n",
       "             -7.8796]],\n",
       " \n",
       "         [[-565.0624,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-565.0624,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-559.5994,    7.3828,    6.3973,  ...,    1.2108,    0.6237,\n",
       "              0.0425],\n",
       "          ...,\n",
       "          [-106.7975,  104.0344,  -63.8039,  ...,    0.2783,   -4.9057,\n",
       "              4.1987],\n",
       "          [-126.6581,   97.0768,  -42.0771,  ...,   19.6952,    0.7437,\n",
       "             -4.1885],\n",
       "          [-118.0180,  123.1944,   -9.6529,  ...,   25.0432,    6.6958,\n",
       "             -2.1894]],\n",
       " \n",
       "         [[-521.0915,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-494.1453,   34.5369,   24.8740,  ...,    0.7725,    0.6556,\n",
       "              0.4473],\n",
       "          [-286.2731,  148.0677,   28.5071,  ...,   -2.1844,   -3.6919,\n",
       "             -3.9181],\n",
       "          ...,\n",
       "          [-521.0915,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-521.0915,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [-521.0915,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]]]),\n",
       " tensor([ 35,  78,  38, 155,  39,  90,  74, 166, 103,  51, 162,  13,  93, 106,\n",
       "          86, 165,   4, 173,  48,  76, 160,  28, 110,  98,  45, 116, 124,  58,\n",
       "          40,   4,  28, 132,  19, 113,  31, 107,  95,   8,  47,  57,  87,  22,\n",
       "          22,  13,  87, 162,  90,  11,  56, 114, 139, 175,  65,  32, 135,  46,\n",
       "         143,  20,  62, 116,  36, 102, 141,  61,  79, 133, 120, 105,   3,  32,\n",
       "          63,  63, 161,  47,   7, 106,  58,  31, 121, 124, 114,   4, 118, 167,\n",
       "          62,  82, 173, 130, 168,  35,  91,  94, 159,  59, 135, 113,  24, 118,\n",
       "         168,  60])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iter(train_loader).next()\n",
    "# train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size,hidden_size, nlayers):\n",
    "        super(DetectionModel,self).__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers=nlayers\n",
    "        self.rnn = nn.LSTM(input_size = embed_size,hidden_size=hidden_size,num_layers=nlayers, bidirectional=True) # Recurrent network\n",
    "        self.scoring = nn.Linear(hidden_size * 2,vocab_size) # Projection layer\n",
    "        \n",
    "    def forward(self, seq_batch):\n",
    "        batch_size = seq_batch.size(1)\n",
    "        embed = seq_batch #L x N x E\n",
    "        hidden = None\n",
    "        output_lstm,hidden = self.rnn(embed,hidden) #L x N x H\n",
    "        output_lstm_flatten = output_lstm.view(-1,self.hidden_size) #(L*N) x H\n",
    "        output_flatten = self.scoring(output_lstm_flatten) #(L*N) x V\n",
    "        return output_flatten.view(-1,batch_size,self.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    batch_id=0\n",
    "    for inputs,targets in train_loader:\n",
    "        batch_loss = []\n",
    "        batch_id+=1\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        outputs = model(inputs) # 3D\n",
    "        outputs = outputs[:, -1, :] # pull out the last layer\n",
    "#         print(outputs.shape)\n",
    "        loss = criterion(outputs,targets) # Loss of the flattened outputs\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "        if batch_id % 20 == 0:\n",
    "            lpw = np.mean(batch_loss)\n",
    "            print(\"At batch\",batch_id)\n",
    "            print(\"Training loss :\",lpw)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    }
   ],
   "source": [
    "langcount = 176\n",
    "model = DetectionModel(langcount,40,256,10)\n",
    "model = model.to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=0.01, weight_decay=1e-6)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py:89: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [86000 x 256], m2: [51200 x 176] at /jet/tmp/build/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-fa2be616b76c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-166-8cb37b5f58ba>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# pull out the last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-325fe71ab43e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq_batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#L x N x H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput_lstm_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(L*N) x H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutput_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_lstm_flatten\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(L*N) x V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [86000 x 256], m2: [51200 x 176] at /jet/tmp/build/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    train_epoch(model, optimizer, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
